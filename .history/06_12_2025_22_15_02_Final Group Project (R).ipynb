{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50fc0e70-e02d-4990-b16f-1f4cc0366356",
   "metadata": {},
   "source": [
    "# Final Group Project Report\n",
    "**Ajay Antonio (90110792), Miria Cho (45167178), Lisa Zhang (5241548), Daniel Xu (17376179)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bdb707-25e4-4527-8aa3-74d2e8d6d964",
   "metadata": {},
   "source": [
    "# I. Introduction \n",
    "\n",
    "In this project, we will be tasked with analyzing a data set in collaboration with a research science group at UBC. Spearheaded by Frank Wood and his team, this project aims to provide insights into the relationships between online gaming and its users, highlighting the often arbitrary forms of data, such as the newsletter subscription, time logged in, and types of players. Through the use of different classification techniques and data recorded from a Minecraft server, we can then make conclusions for more efficient and targeted outreach to players.\n",
    "\n",
    "The broad question that we will be aiming to tackle in our project is **What player characteristics and behaviours are most predictive of subscribing to a game-related newsletter, and how do these features differ between various player types?** \n",
    "\n",
    "More specifically, **Can we predict a player's chance to subscribe to the newsletter based on their total hours played, experience, and age?** In order to answer these questions, multiple steps must be taken to wrangle the data and carry out our predictions. More on this will be discussed later. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3756c3e8-81e5-4dd6-bea5-2ead7b1a492c",
   "metadata": {},
   "source": [
    "## Data Description\n",
    "\n",
    "We will be using the `players.csv` file given by DSCI 100, which provides detailed information and a list of all the unique players collected from the Minecraft Server. The data set has **196** observations and **8** variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe52bde-660a-48ac-a521-b6bc979392e1",
   "metadata": {},
   "source": [
    "#### Table 1 - Variable Names and Types in `players.csv`\n",
    "\n",
    "| Variable     | Type      | Meaning                                                        |\n",
    "|---------------|-----------|----------------------------------------------------------------|\n",
    "| experience    | factor    | Experience of the player (Veteran, Pro, Amateur, Regular)       |\n",
    "| subscribe     | logical   | Status of the player's subscription (TRUE OR FALSE)             |\n",
    "| hashedEmail   | character | Email Addresses of the players (Encoded)                        |\n",
    "| played_hours  | double    | Total hours of Minecraft played                                 |\n",
    "| name          | character | Name of the player                                              |\n",
    "| gender        | factor    | Gender of the player                                            |\n",
    "| Age           | integer   | Age of the player in years                                      |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44adf4fe-b38b-4a16-bd22-ec73c081362b",
   "metadata": {},
   "source": [
    "The second data set that we were given but is not used in the project is `sessions.csv`, which has **1535** observations and **5 variables**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4292df-7d20-4b3a-a8d5-b09e52638d1f",
   "metadata": {},
   "source": [
    "#### Table 2 - Variable Names and Types in `sessions.csv`\n",
    "\n",
    "| Variable           | Type      | Meaning                                                |\n",
    "|--------------------|-----------|--------------------------------------------------------|\n",
    "| hashedEmail        | character | Email Addresses of the players (Encoded)               |\n",
    "| start_time         | character | Start time of gameplay                                 |\n",
    "| end_time           | character | End time of gameplay                                   |\n",
    "| original_start_time| double    | Start time in Epoch Milliseconds                       |\n",
    "| original_end_time  | double    | End time in Epoch Milliseconds                         |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2c65d9-055c-4f47-8a53-89035ef8a355",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries \n",
    "library(tidyverse)\n",
    "library(tidymodels)\n",
    "library(repr)\n",
    "library(RColorBrewer)\n",
    "# formatting graphs\n",
    "options(repr.plot.width = 12, repr.plot.height = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a7d626-6d5c-4690-8f0b-53771a54467e",
   "metadata": {},
   "outputs": [],
   "source": [
    "players <- read_csv(\"players.csv\")\n",
    "summary_stats <- players %>%\n",
    "  summarise(\n",
    "    n_obs = n(),\n",
    "    mean_played_hours = round(mean(played_hours, na.rm = TRUE), 2),\n",
    "    sd_played_hours = round(sd(played_hours, na.rm = TRUE), 2),\n",
    "    min_played_hours = round(min(played_hours, na.rm = TRUE), 2),\n",
    "    max_played_hours = round(max(played_hours, na.rm = TRUE), 2),\n",
    "    mean_age = round(mean(Age, na.rm = TRUE), 2),\n",
    "    sd_age = round(sd(Age, na.rm = TRUE), 2),\n",
    "    min_age = round(min(Age, na.rm = TRUE), 2),\n",
    "    max_age = round(max(Age, na.rm = TRUE), 2)\n",
    "  )\n",
    "\n",
    "summary_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd064246-f98e-4a73-b410-94c3bc9a438a",
   "metadata": {},
   "source": [
    "**Above we have imported the `players.csv` file and outlined the summary statistics (rounded to 2 decimal places).**\n",
    "\n",
    "| Variable           | Amount    | \n",
    "|--------------------|-----------|\n",
    "| mean_played_hours  | 5.85      | \n",
    "| sd_played_hours    | 28.36     |\n",
    "| min_played_hours   | 0         | \n",
    "| max_played_hours   | 223.1     | \n",
    "| mean_age           | 21.14     | \n",
    "| sd_age             | 7.39      | \n",
    "| min_age            | 9         | \n",
    "| max_age            | 58        | "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4868b08-4e2c-46e1-adf3-9e29a8dd5f79",
   "metadata": {},
   "source": [
    "#### Issues and Info about the Dataset:\n",
    "\n",
    "Some potential issues that arise when dealing with the data are: \n",
    "\n",
    "**1:** The data in itself is not tidy, specifically the `sessions.csv` data set, and must be wrangled for simplicity and ease of understandability. For example, the variables of `original_start_time` and `original_end_time` are displayed in the Unix timestamp converter. Furthermore, there are multiple measurements in the columns of `start_time` and `end_time`, which do not adhere to the rule of tidy data - \"each column must have a single variable\".\n",
    "\n",
    "**2:** Since our research question mainly deals with the `players.csv` data set and is focused on experience, age, and hours played, we will not be using the `name` or `gender` variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562768c6-078c-4eb9-a3e2-41d3e0632d8e",
   "metadata": {},
   "source": [
    "# II. Methods & Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b987c2-756a-4fb9-9f5b-0df2d3fab776",
   "metadata": {},
   "source": [
    "The goal of this project is to determine whether we can predict a player's likelihood of subscribing to the newsletter based on their total playtime `played_hours`, experience level, and age. This analysis will help identify the player characteristics most associated with subscription behavior and can provide useful insights for retention and marketing strategies. \n",
    "\n",
    "The combination of **behavioral data** `played_hours`, **experience data** `experience`, and **demographic data** `Age` allows for well-rounded analysis of factors influencing subscription. \n",
    "\n",
    "`played_hours` = indicates player engagement; higher playtime may reflect greater interest and likelihood to subscribe.\n",
    "\n",
    "`experience` = captures skill and familiarity with the game - experienced players may be more connected to the community. \n",
    "\n",
    "`age` = represents demographic variation - certain age groups may have different levels of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4439d550-18fe-4e10-81d8-7a171a9e7a1f",
   "metadata": {},
   "source": [
    "#### Data Wrangling Plan \n",
    "\n",
    "Before applying our predictive model, we will wrangle the data to clean and prepare it:\n",
    "\n",
    "**1**: **Clean and Inspect the Data**:\n",
    "- Remove the irrelevant variables like `name` and `hashedEmail` that do not contribute to the prediction.\n",
    "- Check for missing or inconsistent values like blanks or NA in our chosen variables.\n",
    "- Convert key variables like `subscribe` into factors for classification.\n",
    "\n",
    "**2**: **Select Relevant Variables**:\n",
    "- Since our focus is on predicting `subscribe`, we must remove the other variables using select."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ed05c6-693c-4535-ba8f-f5d56bd8b014",
   "metadata": {},
   "source": [
    "**3**: **Data Splitting and Summary of Training Data**\n",
    "-  Use `initial_split()` to divide the dataset into training and testing sets.\n",
    "- Generate summary statistics and visualizations to understand the relationships between our variables.\n",
    "- Plot scatterplots and density plots to examine the potential seperability of classes and identify any visible trends or patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae58e11e-5fd9-4a21-bf16-18b9950ea17f",
   "metadata": {},
   "source": [
    "#### Classification Method: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832b003c-9178-44ef-9cc4-eea1282e1095",
   "metadata": {},
   "source": [
    "The method that we have chosen to address our question of interest is **K-Nearest Neighbors (KNN)**. KNN is a non-parametric method, which means it does not make strict assumptions about data distributions and does not limit the data being classified to be linear or display a linear relationship. \n",
    "\n",
    "KNN predicts its class membership based on similarity in the feature space, and is compatible with our smaller dataset. Thus, KNN is well-suited for predicting a player's likelihood of subscribing based on behavioural and demographic features. \n",
    "\n",
    "**Some assumptions that are required to apply KNN include:**\n",
    "\n",
    "- **Feature scaling is essential** to ensure that there are no massive amounts in distance that may tamper with results.\n",
    "- The training data must capture the variety of relationships that we expect to see in new data.\n",
    "- **Removal of major outliers**, as this can distort distance calculations.\n",
    "- **The choice of K is crucial** - as small K -> overfitting; large K -> underfitting. Optimal K must be tuned via cross-validation.\n",
    "\n",
    "We will be evaluating and selecting the model based on cross-validated accuracy - specifically, a **5-fold cross-validation** on the training data. We will then split the data before modeling into training (80%) and testing (20%) sets and use stratification on `subscribe` to maintain class balance. \n",
    "\n",
    "Finally, we will train and tune our model through these steps:\n",
    "\n",
    "- Tune K using cross-validation\n",
    "- Train the final model using the best K. \n",
    "- Evaluate model performance on the test set using accuracy, visual inspection, and the confusion matrix.  \n",
    "\n",
    "- ### Logistic regression classifier (comparison model)\n",
    "\n",
    "In addition to the KNN classifier introduced in class, we also fitted a logistic regression model to the same training data as a comparison. Logistic regression models the log-odds of subscribing as a linear combination of the predictors. This allows us to interpret the direction and relative strength of the association between each predictor and the probability of subscription.\n",
    "\n",
    "For the logistic regression model we used the same set of predictors as in the KNN model. Categorical variables were encoded using dummy variables, and numeric predictors were kept on their original scale (we also checked that standardising them did not materially change the results). The model was fitted on the training set, and we then used the fitted model to predict class labels on the test set.\n",
    "\n",
    "We compared the logistic regression and KNN models using the same test set and the same performance metrics (test accuracy, confusion matrix, and misclassification rate). This allowed us to assess not only which model predicts subscription better, but also to discuss the trade-off between predictive performance (KNN) and interpretability (logistic regression).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5040e1cb-d0fb-4cd1-9212-dcec3cfcb417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries \n",
    "library(tidyverse)\n",
    "library(tidymodels)\n",
    "library(repr)\n",
    "library(RColorBrewer)\n",
    "# formatting graphs\n",
    "options(repr.plot.width = 12, repr.plot.height = 6)\n",
    "\n",
    "# We had already demonstrated that the dataset can be loaded into R earlier.\n",
    "\n",
    "# Data Cleaning and Wrangling\n",
    "players_new <- players %>%\n",
    "    select(subscribe, played_hours, experience, Age) |>\n",
    "    filter(!is.na(Age), played_hours > 0) |> \n",
    "    mutate(subscribe = as.factor(subscribe))\n",
    "\n",
    "head(players_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e7ca1a-9735-49bc-8e9a-60fb42492dea",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51de9d30-b209-4cd4-90ec-4cc117e1dcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the mean value for each quantitative variable in the players\n",
    "\n",
    "mean_table <- players %>%\n",
    "    summarise(across(where(is.numeric), ~mean(.x, na.rm = TRUE))) %>%\n",
    "    pivot_longer(everything(), names_to = \"Variable\", values_to = \"Mean\") %>%\n",
    "    mutate(Mean = round(Mean, 2))\n",
    "\n",
    "mean_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2fef08-8d9a-4bf2-867a-b4cd5cd90201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizations to better understand the data.\n",
    "\n",
    "# use a log scale to handle the extreme skew and zero values in the data\n",
    "minecraft_plot1 <- ggplot(players_new, aes(x = subscribe, y = played_hours, fill = subscribe)) +\n",
    "  geom_boxplot(outlier.shape = NA, alpha = 0.6) + # Boxplot summarizes distribution\n",
    "  geom_point(alpha = 0.4, color = \"#2C3E50\") + # Point shows actual data density\n",
    "  scale_y_continuous(trans = \"log1p\", breaks = c(0, 1, 10, 100, 200)) + # Log transformation for readability\n",
    "  labs(\n",
    "    title = \"Figure 1: Player Engagement vs. Subscription (Log Scale)\",\n",
    "    subtitle = \"Subscribers exhibit significantly higher variability and extreme play times\",\n",
    "    x = \"Subscribed\",\n",
    "    y = \"Played Hours (Log Scale)\"\n",
    "  )\n",
    "\n",
    "minecraft_plot1\n",
    "\n",
    "# Detailed statistics for played hours to support the Discussion\n",
    "hours_stats <- players_new %>%\n",
    "  group_by(subscribe) %>%\n",
    "  summarise(\n",
    "    count = n(),\n",
    "    median_hours = median(played_hours),\n",
    "    mean_hours = mean(played_hours),\n",
    "    max_hours = max(played_hours),\n",
    "    # Percentage of players with effectively zero playtime\n",
    "    pct_inactive = mean(played_hours == 0) * 100\n",
    "  )\n",
    "\n",
    "hours_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ede87fa-e46a-4063-a16a-5108276562ec",
   "metadata": {},
   "source": [
    "**Figure 1**: Note that the Y-axis uses a logarithmic scale because the difference in play times is extreme (ranging from 0 to over 200 hours).  \n",
    "There is a clear \"ceiling\" for non subscribers. While low playtime does not guarantee a player won't subscribe (many subscribers also have low hours), high playtime is a near perfect predictor of subscription. Essentially, the most dedicated players are almost exclusively subscribers, whereas casual players are a mix of both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746830ac-e96b-41bc-ba7d-e2290bf19008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Subscription by Experience\n",
    "minecraft_plot2 <- ggplot(players, aes(x = experience, fill = factor(subscribe))) +\n",
    "  geom_bar(position = \"dodge\") +\n",
    "  labs(title = \"Figure 2: Newsletter Subscription by Experience Level\", \n",
    "       x = \"Experience\", fill = \"Subscribed\")\n",
    "    theme(text = element_text(size = 14))\n",
    "\n",
    "minecraft_plot2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120ea490-980a-4aab-8688-39295fc6f393",
   "metadata": {},
   "source": [
    "**Figure 2**: Subscription rates follow a concave pattern: amateurs and veteran players subscribe more often, especially amateurs, while mid-level players show noticeably lower subscription counts. This non-linear trend suggests that experience level may influence subscription behavior in a more complex way than expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d25a4b-ec7f-4b0d-b536-09ae4b5c5f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram: Subscription by Age Distribution\n",
    "minecraft_plot3 <- ggplot(players, aes(x = Age, fill = factor(subscribe))) +\n",
    "  geom_histogram(bins = 10, position = \"stack\") +\n",
    "  labs(title = \"Figure 3: Subscription by Age Distribution\", x = \"Age\", y = \"Count\")\n",
    "    theme(text = element_text(size = 14))\n",
    "\n",
    "minecraft_plot3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f936ed-2a32-418b-822c-cb52f7050b89",
   "metadata": {},
   "source": [
    "**Figure 3**: Here we can see that the Age vs Subscrition graph only highlights and focuses on a significant number of the player base - that being those who are 17. Therefore, this may pose an issue when classifying and impacting our precision/recall values. \n",
    "\n",
    "Additionally, the majority of participants' ages range from 17-28, so we may not be able to display results for experience levels of people outside of the age range. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f88b0c-d7a5-4bde-a7a7-70a38a8d3620",
   "metadata": {},
   "source": [
    "## Analysis  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bbdc29-d3c0-4e59-af08-422ab822c9f6",
   "metadata": {},
   "source": [
    "**K-Nearest Neighbours (KNN)**\n",
    "\n",
    "To predict the binary outcome (subscribe: TRUE/FALSE), we employed a K-Nearest Neighbours (KNN) classifier. This method predicts a player’s subscription status based on the subscription behaviour of the most similar players in the dataset, using their Age, played_hours, and experience.\n",
    "\n",
    "**Procedure:**\n",
    "\n",
    "Data Splitting: We used the same data split as for logistic regression, with 75% of the data used for training and 25% held out for testing to evaluate performance on unseen data.\n",
    "\n",
    "Preprocessing: Because KNN is distance-based and sensitive to the scale of predictors, we standardised the numeric variables (Age, played_hours, and experience) in the training set and applied the same transformation to the test set.\n",
    "\n",
    "Model Specification: We specified a KNN classification model using the tidymodels framework.\n",
    "\n",
    "Model Tuning: Using K-fold cross-validation on the training data, we compared different values of K and selected the one that gave the best average classification performance.\n",
    "\n",
    "Training: The final KNN model with the chosen K was then fitted on the full training set, and its predictive performance was evaluated on the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2c4cf0-5404-40a2-a485-0e900660f2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidymodels)\n",
    "\n",
    "set.seed(123)\n",
    "\n",
    "# 1. Split the data into training (75%) and test (25%) sets,\n",
    "sub_split  <- initial_split(players_new, prop = 0.75, strata = subscribe)\n",
    "sub_train  <- training(sub_split)\n",
    "sub_test   <- testing(sub_split)\n",
    "\n",
    "# 2. Define a recipe:\n",
    "knn_recipe <- recipe(subscribe ~.,\n",
    "                     data = sub_train) |>\n",
    "  step_normalize(all_numeric_predictors())\n",
    "\n",
    "# 3. Specify the KNN classification model.\n",
    "knn_spec <- nearest_neighbor(\n",
    "  mode        = \"classification\",\n",
    "  neighbors   = tune(),        # K will be selected via cross-validation\n",
    "  weight_func = \"rectangular\",\n",
    "  dist_power  = 2\n",
    ") |>\n",
    "  set_engine(\"kknn\")\n",
    "\n",
    "# 4. Create a workflow that combines the recipe and the model specification.\n",
    "knn_wf <- workflow() |>\n",
    "  add_model(knn_spec) |>\n",
    "  add_recipe(knn_recipe)\n",
    "\n",
    "# 5. Set up 5-fold cross-validation on the training set.\n",
    "set.seed(123)\n",
    "knn_folds <- vfold_cv(sub_train, v = 5, strata = subscribe)\n",
    "\n",
    "# 6. Define a grid of candidate K values to try.\n",
    "knn_grid <- tibble(neighbors = seq(1, 31, by = 2))  # K = 1, 3, 5, ..., 31\n",
    "\n",
    "# 7. Tune the KNN model over the grid of K values using cross-validation.\n",
    "knn_tuned <- tune_grid(\n",
    "  knn_wf,\n",
    "  resamples = knn_folds,\n",
    "  grid      = knn_grid,\n",
    "  metrics   = metric_set(accuracy)\n",
    ")\n",
    "\n",
    "# 8. Inspect the best-performing K values according to accuracy.\n",
    "show_best(knn_tuned, \"accuracy\")\n",
    "\n",
    "# 9. Select the single best K based on cross-validated accuracy.\n",
    "best_knn <- select_best(knn_tuned, \"accuracy\")\n",
    "\n",
    "# 10. Finalize the workflow by plugging in the best K.\n",
    "final_knn_wf <- finalize_workflow(knn_wf, best_knn)\n",
    "\n",
    "# 11. Fit the final KNN model on the full training set.\n",
    "final_knn_fit <- fit(final_knn_wf, data = sub_train)\n",
    "\n",
    "# 12. Generate predictions on the test set:\n",
    "knn_test_preds <- predict(final_knn_fit, sub_test, type = \"prob\") |>\n",
    "  bind_cols(predict(final_knn_fit, sub_test)) |>\n",
    "  bind_cols(sub_test |> select(subscribe))\n",
    "\n",
    "# 13. Compute overall performance metrics on the test set,\n",
    "knn_metrics <- knn_test_preds |>\n",
    "  metrics(truth = subscribe, estimate = .pred_class)\n",
    "\n",
    "# 14. Create a confusion matrix to see how the model performs\n",
    "#     on each class (subscribe = TRUE/FALSE).\n",
    "knn_conf_mat <- knn_test_preds |>\n",
    "  conf_mat(truth = subscribe, estimate = .pred_class)\n",
    "\n",
    "knn_metrics\n",
    "knn_conf_mat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51bb884-4698-4c89-8568-1ea9357dba18",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ggplot2)\n",
    "\n",
    "# Collect cross-validation metrics for each value of K\n",
    "knn_cv_results <- knn_tuned |>\n",
    "  collect_metrics() |>\n",
    "  filter(.metric == \"accuracy\")\n",
    "\n",
    "\n",
    "# Plot mean accuracy vs. number of neighbours (K)\n",
    "ggplot(knn_cv_results, aes(x = neighbors, y = mean)) +\n",
    "  geom_line() +                          # connect the points with a line\n",
    "  geom_point() +                         # show each K as a point\n",
    "  geom_errorbar(aes(ymin = mean - std_err,\n",
    "                    ymax = mean + std_err),\n",
    "                width = 0.3) +           # add error bars for uncertainty\n",
    "  labs(\n",
    "    title = \"Figure 4: KNN cross-validated accuracy\",\n",
    "    x = \"Number of neighbours (K)\",\n",
    "    y = \"Mean CV accuracy\"\n",
    "  ) +\n",
    "  theme_minimal()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0623ce85-0e2d-4384-839e-750f2ada71f5",
   "metadata": {},
   "source": [
    "Figure 4: The cross-validation results in Figure X show that the KNN classifier performs poorly for very small values of K, but its mean accuracy increases as K becomes larger. From about K=9 onwards, the cross-validated accuracy stabilises around 0.78 with relatively small standard errors. This suggests that using more neighbours helps to smooth out noise in individual observations and leads to more reliable predictions. We therefore chose a value of K in this flat region of the curve (e.g., K=15), where the model achieves high and stable cross-validated accuracy without being overly sensitive to small changes in K."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1345b842-69ef-404a-baf9-212d1fdafcce",
   "metadata": {},
   "source": [
    "### Logistic Regression  \n",
    "To predict the binary outcome (subscribe: TRUE/FALSE), we also employed a Logistic Regression model. This method allows us to estimate the probability of a player subscribing based on the explanatory variables (Age, played_hours, and experience).  \n",
    "\n",
    "#### Procedure:\n",
    "\n",
    "1. Data Splitting: The data was split into training (75%) and testing (25%) sets to evaluate model performance on unseen data.\n",
    "\n",
    "2. Model Specification: We used the glm engine in the tidymodels framework.\n",
    "\n",
    "3. Training: The model was trained using the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1aad6f-84a1-487c-a82c-e31eef40853f",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(123) # Ensure reproducibility\n",
    "\n",
    "# 1. Split the data into training and testing sets\n",
    "data_split <- initial_split(players_new, prop = 0.75, strata = subscribe)\n",
    "train_data <- training(data_split)\n",
    "test_data  <- testing(data_split)\n",
    "\n",
    "# 2. Define the model specification\n",
    "log_mod <- logistic_reg() %>%\n",
    "  set_engine(\"glm\") %>%\n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# 3. Create a recipe for preprocessing\n",
    "# We convert nominal predictors (experience, gender) into dummy variables\n",
    "player_recipe <- recipe(subscribe ~ ., data = train_data) %>%\n",
    "  step_dummy(all_nominal_predictors())\n",
    "\n",
    "# 4. Create a workflow\n",
    "player_workflow <- workflow() %>%\n",
    "  add_model(log_mod) %>%\n",
    "  add_recipe(player_recipe)\n",
    "\n",
    "# 5. Fit the model to the training data\n",
    "player_fit <- player_workflow %>%\n",
    "  fit(data = train_data)\n",
    "\n",
    "# Output the model coefficients (Reasoning)\n",
    "tidy(player_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0e431c-0721-4307-a69e-68daca21e059",
   "metadata": {},
   "source": [
    "We evaluated the model using the testing set. We visualized the results using a Confusion Matrix to see true positives and false negatives, and calculated the overall accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9d69e6-c66d-438c-bb64-8b5c657786ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test data\n",
    "predictions <- player_fit %>%\n",
    "  predict(test_data) %>%\n",
    "  bind_cols(test_data)\n",
    "\n",
    "# Confusion Matrix Visualization\n",
    "conf_mat <- predictions %>%\n",
    "  conf_mat(truth = subscribe, estimate = .pred_class)\n",
    "\n",
    "# Figure 5: Heatmap of the Confusion Matrix\n",
    "autoplot(conf_mat, type = \"heatmap\") +\n",
    "  labs(title = \"Figure 5: Confusion Matrix of Predictions\")\n",
    "\n",
    "# Calculate Accuracy\n",
    "accuracy_metric <- predictions %>%\n",
    "  metrics(truth = subscribe, estimate = .pred_class) %>%\n",
    "  filter(.metric == \"accuracy\")\n",
    "\n",
    "print(accuracy_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e859f6-ea14-4850-87f1-815272cdcf19",
   "metadata": {},
   "source": [
    "# III. Discussion\n",
    "### Summary of Findings  \n",
    "Our analysis aimed to identify predictors for newsletter subscriptions. Based on the Exploratory Data Analysis and the Logistic Regression coefficients, we observed specific trends. For example, preliminary EDA (Figure 2) suggested that \"Veterans\" and \"Amateurs\" constituted a large portion of the subscriber base. The logistic regression model provided quantitative backing to these observations, assigning weights (coefficients) to the experience levels and age. It showed that while age seemed to have some impact on subscription chances, largely veterency played a much stronger role in suscribes. \n",
    "\n",
    "### Expectations vs. Reality  \n",
    "We expected played_hours to be a strong predictor, assuming that players who play more are more invested in the game's ecosystem. However, the high variance in play time (shown in the summary statistics) likely introduced noise, making it a less reliable predictor than categorical experience levels, which is much more concrete. The model's accuracy on the test set indicates how well these specific demographics generalize to new players, higher accuracy levels returning more response from the playerbase. \n",
    "\n",
    "### Impact  \n",
    "These findings have immediate implications for the marketing team. If specific experience levels (e.g., Veterans) are statistically more likely to subscribe, resources should not be wasted aggressively targeting them as they are already likely to convert. Instead, efforts can be focused on the segments identified as \"low probability\" subscribers to increase their engagement, or simply accepted as a segment that prefers other communication channels. Examples of these parties are low veterancy players, or possibly players who seem to intentionally have lower playtimes. \n",
    "\n",
    "### Future Questions  \n",
    "1. Content Relevance: Do younger players prefer real time communication (such as social media) over newsletters?\n",
    "\n",
    "2. Churn Analysis: Does subscription actually lead to longer retention, or is it just a signal of existing loyalty? Future analysis should treat subscribe as a predictor for retention_rate.\n",
    "\n",
    "3. Feature Engineering: Could early-game behavior, session frequency, or engagement bursts serve as better real-time predictors?\n",
    "\n",
    "4. Player Motivations: What role do intrinsic motivations, such as competition, exploration, or social play—play in subscription probability? Is this measurable via this data set?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e14f5b8-c8c1-4b72-8547-31176f9270bb",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3770b420-3f8c-4e13-97e7-6e8147747b09",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "Pacific Laboratory for Artificial Intelligence. (2025, September 11). *Pacific Laboratory for Artificial Intelligence.* https://plai.cs.ubc.ca/ \n",
    "\n",
    "*PLAICraft. (n.d.).* https://plaicraft.ai/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
